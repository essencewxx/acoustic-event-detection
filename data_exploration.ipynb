{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674b54bc",
   "metadata": {},
   "source": [
    "# Undersand the data and utils functions\n",
    "\n",
    "- wave_to_csv: reurn a dataframe with time stamp (based on the sameple rate) and amplitude value for each channels at that time. \n",
    "    - For Mono Audio: If the WAV file is mono (single channel), the array will be one-dimensional with shape (num_samples,). For Stereo or Multi-Channel Audio: If the WAV file has multiple channels (e.g., stereo), the array will be two-dimensional with shape (num_samples, num_channels). For stereo audio, num_channels is 2.\n",
    "    - Amplitude Values: the amplitude values range between the minimum and maximum values representable by that type (e.g., -32,768 to 32,767 for int16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4ec503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, fftfreq\n",
    "import src.label_parsing as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4256ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#erocshadow_cough_wav_filepath = \"data/raw/positive/coughing/108017__erocshadow__cough/data.wav\"\n",
    "erocshadow_cough_wav_filepath = \"data/raw/positive/coughing/mix2_cough_train/data.wav\"\n",
    "erocshadow_cough_df = utils.wave_to_csv(erocshadow_cough_wav_filepath)\n",
    "display(erocshadow_cough_df.head())\n",
    "display(erocshadow_cough_df.describe())\n",
    "\n",
    "batch_cough_wav_filepath = \"data/raw/positive/coughing_batch_2/coughconcat0/data.wav\"\n",
    "batch_cough_df = utils.wave_to_csv(batch_cough_wav_filepath)\n",
    "#display(batch_cough_df.head())\n",
    "#batch_cough_df.describe()\n",
    "\n",
    "mic_tap_wav_filepath = \"data/raw/negative/mic_tapping/studio/53586__3dward0__tabletap/data.wav\"\n",
    "mic_tap_df = utils.wave_to_csv(mic_tap_wav_filepath)\n",
    "#display(mic_tap_df.head())\n",
    "#mic_tap_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f60d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(data_df, sameple_name):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(data_df['CH0'])\n",
    "    plt.title(f'Audio Waveform of a {sameple_name} exmaple')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Amplitude')\n",
    "    return 0\n",
    "\n",
    "plot_waveform(erocshadow_cough_df, 'cough')\n",
    "plot_waveform(batch_cough_df, 'batch_cough')\n",
    "plot_waveform(mic_tap_df, 'mic_tap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrum(data_df, sameple_name):\n",
    "    duration = data_df.iloc[1,0]\n",
    "    N = len(data_df)\n",
    "    yf = fft(data_df)\n",
    "    xf = fftfreq(N, duration)\n",
    "\n",
    "    # Only take the positive frequencies\n",
    "    idx = np.arange(1, N//2)\n",
    "\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(xf[idx], np.abs(yf[idx]))\n",
    "    plt.title(f'Frequency Spectrum of a {sameple_name} sample')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.show()\n",
    "    return 0\n",
    "\n",
    "plot_spectrum(erocshadow_cough_df, 'cough')\n",
    "plot_spectrum(batch_cough_df, 'batch_cough')\n",
    "plot_spectrum(mic_tap_df, 'mic_tap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68321496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(erocshadow_cough_df['CH0'], bins=50, color='gray')\n",
    "plt.title('Amplitude Distribution')\n",
    "plt.xlabel('Amplitude Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef85927",
   "metadata": {},
   "outputs": [],
   "source": [
    "erocshadow_cough_label_filepath = \"data/raw/positive/coughing/108017__erocshadow__cough/label.label\"\n",
    "erocshadow_cough_label_df = pd.read_csv(erocshadow_cough_label_filepath)\n",
    "erocshadow_cough_label_vector_df = utils.convert_track_to_label(erocshadow_cough_df, erocshadow_cough_label_df)\n",
    "len(erocshadow_cough_label_vector_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the label\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(erocshadow_cough_label_vector_df)\n",
    "plt.title('Audio Waveform')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
