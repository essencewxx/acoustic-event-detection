{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import src.load_data as load_data\n",
    "import src.feature_extraction as feature_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_sample_folder_batch1 = \"data/raw/positive/coughing\"\n",
    "positive_segments_batch1 = load_data.load_positive_data(positive_sample_folder_batch1)\n",
    "print(positive_segments_batch1[0]) # The first cough in mix2_cough_train, 13363 samples, last 0.835s\n",
    "print(f\"Number of positive samples from coughing folder is {len(positive_segments_batch1)}\") \n",
    "load_data.get_segment_statistics(positive_segments_batch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_sample_folder_batch2 = \"data/raw/positive/coughing_batch_2\"\n",
    "positive_segments_batch2 = load_data.load_positive_data(positive_sample_folder_batch2)\n",
    "print(positive_segments_batch2[0]) # The first cough in mix2_cough_train, 13363 samples, last 0.835s\n",
    "print(f\"Number of positive samples from coughing folder is {len(positive_segments_batch2)}\")\n",
    "load_data.get_segment_statistics(positive_segments_batch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_segments_batch1 = load_data.load_negative_data(positive_sample_folder_batch1)\n",
    "print(negative_segments_batch1[0])\n",
    "print(f\"Number of negative samples from coughing folder batch1 is {len(negative_segments_batch1)}\")\n",
    "load_data.get_segment_statistics(negative_segments_batch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_segments_batch2 = load_data.load_negative_data(positive_sample_folder_batch2, segments_per_file=2, seed=99)\n",
    "print(negative_segments_batch2[0])\n",
    "print(f\"Number of positive samples from coughing folder is {len(negative_segments_batch2)}\")\n",
    "load_data.get_segment_statistics(negative_segments_batch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sample_folder_laugh = \"data/raw/negative/laugh\"\n",
    "negative_segments_laugh = load_data.load_negative_data(negative_sample_folder_laugh, segments_per_file=45, seed=42)\n",
    "print(f\"Number of negative samples from laugh folder is {len(negative_segments_laugh)}\")\n",
    "load_data.get_segment_statistics(negative_segments_laugh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sample_folder_mic_tap = \"data/raw/negative/mic_tapping/studio\"\n",
    "negative_segments_mic_tap = load_data.load_negative_data(negative_sample_folder_mic_tap, segments_per_file=40, seed=123)\n",
    "print(f\"Number of negative samples from mic tapping folder is {len(negative_segments_mic_tap)}\")\n",
    "load_data.get_segment_statistics(negative_segments_mic_tap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sample_folder_people_talk = \"data/raw/negative/people_talking\"\n",
    "negative_segments_people_talk = load_data.load_negative_data(negative_sample_folder_people_talk, segments_per_file=35, seed=1)\n",
    "print(f\"Number of negative samples from people talk folder is {len(negative_segments_people_talk)}\")\n",
    "load_data.get_segment_statistics(negative_segments_people_talk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_segments = positive_segments_batch1 + positive_segments_batch2\n",
    "negative_segments = negative_segments_laugh + negative_segments_mic_tap + negative_segments_people_talk\n",
    "print(f\"type of a positive segment: {type(positive_segments[10])}, and its shape is {positive_segments[10].shape}\")\n",
    "print(f\"type of a negetive segment: {type(negative_segments[10])}, and its shape is {negative_segments[10].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_features_mel = []\n",
    "for segment in positive_segments_batch1:\n",
    "    feature = feature_extraction.extract_mel_spectrogram(segment, sr=16000)\n",
    "    positive_features_mel.append(feature)\n",
    "\n",
    "positive_features_mfcc = []\n",
    "for segment in positive_segments_batch1:\n",
    "    feature = feature_extraction.extract_mfcc(segment, sr=16000)\n",
    "    positive_features_mfcc.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_features_mel = []\n",
    "for segment in negative_segments_laugh:\n",
    "    feature = feature_extraction.extract_mel_spectrogram(segment, sr=16000)\n",
    "    negative_features_mel.append(feature)\n",
    "\n",
    "negative_features_mfcc = []\n",
    "for segment in negative_segments_laugh:\n",
    "    feature = feature_extraction.extract_mfcc(segment, sr=16000)\n",
    "    negative_features_mfcc.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction.plot_log_spectrogram(positive_features_mel[1])\n",
    "feature_extraction.plot_mfccs(positive_features_mfcc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction.plot_log_spectrogram(negative_features_mel[10])\n",
    "feature_extraction.plot_mfccs(negative_features_mfcc[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, val, test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Extract features\n",
    "X_positive = feature_extraction.extract_agg_mfcc(positive_segments)\n",
    "X_negative = feature_extraction.extract_agg_mfcc(negative_segments)\n",
    "\n",
    "# Create labels: 1 for cough, 0 for not cough\n",
    "y_positive = np.ones(len(X_positive))\n",
    "y_negative = np.zeros(len(X_negative))\n",
    "\n",
    "# Combine the data\n",
    "X = np.vstack((X_positive, X_negative))\n",
    "y = np.concatenate((y_positive, y_negative))\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split Data into Training(70%), Validation(15%), and Test Sets(15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, evaluate and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train SVM with GridSearch\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(probability=True, random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "# Use the Best Estimator\n",
    "best_svm = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Validate the Model\n",
    "y_val_pred = best_svm.predict(X_val)\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Test the Model\n",
    "y_test_pred = best_svm.predict(X_test)\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Paths to save model and scaler\n",
    "SCALER_PATH = 'model/svm/scaler.pkl'\n",
    "MODEL_PATH = 'model/svm/svm_model.pkl'\n",
    "\n",
    "joblib.dump(scaler, SCALER_PATH)\n",
    "joblib.dump(best_svm, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained Model and Scaler\n",
    "# Paths to saved model and scaler\n",
    "SCALER_PATH = 'model/svm/scaler.pkl'\n",
    "MODEL_PATH = 'model/svm/svm_model.pkl'\n",
    "\n",
    "# Load the trained SVM model and scaler\n",
    "svm_model = joblib.load(MODEL_PATH)\n",
    "scaler = joblib.load(SCALER_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get audio segments from new .wav file\n",
    "cough_file1_path = \"data/raw/test/mix2_cough_train/data.wav\"\n",
    "cough_file1_segments = load_data.load_and_segment_wav(cough_file1_path, segment_duration=0.1)\n",
    "# Verify the segments\n",
    "print(f\"Total Segments: {len(cough_file1_segments)}\")\n",
    "print(f\"Shape of first segment: {cough_file1_segments[0].shape}\")\n",
    "\n",
    "# Extract features from the new audio segments\n",
    "X = feature_extraction.extract_agg_mfcc(cough_file1_segments)\n",
    "print(f\"Feature Matrix Shape: {X.shape}\")\n",
    "\n",
    "# Scale the features using the trained scaler\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Predict labels\n",
    "y_pred = svm_model.predict(X_scaled)\n",
    "\n",
    "# Get prediction probabilities\n",
    "y_pred_probs = svm_model.predict_proba(X_scaled)[:, 1]  # Probability of 'Cough'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Map predictions back to the audio timeline\n",
    "segments = cough_file1_segments\n",
    "num_segments = len(segments)\n",
    "sr=16000\n",
    "segment_duration=0.1\n",
    "hop_length=segment_duration * sr\n",
    "segment_times = []\n",
    "for i in range(num_segments):\n",
    "    start_time = i * hop_length / sr\n",
    "    segment_times.append((start_time, segment_duration))\n",
    "\n",
    "# Create a DataFrame for results\n",
    "results_df = pd.DataFrame(segment_times, columns=['Time(Seconds)', 'Length(Seconds)'])\n",
    "results_df['Label(string)'] = np.where(y_pred == 1, \"cough\", \"not cough\")\n",
    "results_df['Confidence(double)'] = y_pred_probs\n",
    "\n",
    "cough_df = results_df[results_df['Label(string)'] == 'cough']\n",
    "cough_df.to_csv(\"data/raw/test/mix2_cough_train/testlabel.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
